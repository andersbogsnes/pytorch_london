{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ (w_1x_i) * w_2 == w_1*w_2*x_i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our dataset\n",
    "boston = load_boston()\n",
    "train_x, test_x, train_y, test_y = train_test_split(boston.data, boston.target, random_state=seed)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_x = torch.tensor(scaler.fit_transform(train_x), dtype=torch.float)\n",
    "test_x = torch.tensor(scaler.transform(test_x), dtype=torch.float)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float).view(-1, 1)\n",
    "test_y = torch.tensor(test_y, dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "layer_size = train_x.shape[1]\n",
    "lr = 0.05\n",
    "epochs = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "w = torch.randn(layer_size, 1, dtype=torch.float) / math.sqrt(layer_size)\n",
    "w.requires_grad_()\n",
    "b = torch.zeros(1, requires_grad=True, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def mean_squared_error(y_hat, y):\n",
    "    return ((y_hat - y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 582.6249389648438 Test Loss: 246.31898498535156\n",
      "Epoch: 10 Train Loss: 95.832275390625 Test Loss: 75.27898406982422\n",
      "Epoch: 20 Train Loss: 75.61251068115234 Test Loss: 58.562835693359375\n",
      "Epoch: 30 Train Loss: 64.2797622680664 Test Loss: 49.8370475769043\n",
      "Epoch: 40 Train Loss: 57.49154281616211 Test Loss: 45.147666931152344\n",
      "Epoch: 50 Train Loss: 53.082279205322266 Test Loss: 42.411781311035156\n",
      "Epoch: 60 Train Loss: 49.95682907104492 Test Loss: 40.62007522583008\n",
      "Epoch: 70 Train Loss: 47.55707931518555 Test Loss: 39.29010009765625\n",
      "Epoch: 80 Train Loss: 45.59485626220703 Test Loss: 38.19508743286133\n",
      "Epoch: 90 Train Loss: 43.91814041137695 Test Loss: 37.230743408203125\n",
      "Epoch: 100 Train Loss: 42.443965911865234 Test Loss: 36.350303649902344\n",
      "Epoch: 110 Train Loss: 41.12471008300781 Test Loss: 35.533355712890625\n",
      "Epoch: 120 Train Loss: 39.93116760253906 Test Loss: 34.770965576171875\n",
      "Epoch: 130 Train Loss: 38.84393310546875 Test Loss: 34.058868408203125\n",
      "Epoch: 140 Train Loss: 37.84906005859375 Test Loss: 33.39447021484375\n",
      "Epoch: 150 Train Loss: 36.935829162597656 Test Loss: 32.77558135986328\n",
      "Epoch: 160 Train Loss: 36.09550476074219 Test Loss: 32.199974060058594\n",
      "Epoch: 170 Train Loss: 35.320770263671875 Test Loss: 31.665285110473633\n",
      "Epoch: 180 Train Loss: 34.60526657104492 Test Loss: 31.169069290161133\n",
      "Epoch: 190 Train Loss: 33.94346618652344 Test Loss: 30.70882797241211\n",
      "Epoch: 200 Train Loss: 33.330448150634766 Test Loss: 30.282073974609375\n",
      "Epoch: 210 Train Loss: 32.76185607910156 Test Loss: 29.88640594482422\n",
      "Epoch: 220 Train Loss: 32.233787536621094 Test Loss: 29.519548416137695\n",
      "Epoch: 230 Train Loss: 31.742765426635742 Test Loss: 29.179317474365234\n",
      "Epoch: 240 Train Loss: 31.285640716552734 Test Loss: 28.863704681396484\n",
      "Epoch: 250 Train Loss: 30.859586715698242 Test Loss: 28.57080841064453\n",
      "Epoch: 260 Train Loss: 30.462053298950195 Test Loss: 28.298887252807617\n",
      "Epoch: 270 Train Loss: 30.09075164794922 Test Loss: 28.04634666442871\n",
      "Epoch: 280 Train Loss: 29.743587493896484 Test Loss: 27.81167984008789\n",
      "Epoch: 290 Train Loss: 29.418672561645508 Test Loss: 27.593544006347656\n",
      "Epoch: 300 Train Loss: 29.11429214477539 Test Loss: 27.390666961669922\n",
      "Epoch: 310 Train Loss: 28.828880310058594 Test Loss: 27.2019100189209\n",
      "Epoch: 320 Train Loss: 28.561033248901367 Test Loss: 27.026195526123047\n",
      "Epoch: 330 Train Loss: 28.309431076049805 Test Loss: 26.862567901611328\n",
      "Epoch: 340 Train Loss: 28.072904586791992 Test Loss: 26.710119247436523\n",
      "Epoch: 350 Train Loss: 27.850358963012695 Test Loss: 26.56803321838379\n",
      "Epoch: 360 Train Loss: 27.64081382751465 Test Loss: 26.435544967651367\n",
      "Epoch: 370 Train Loss: 27.44333839416504 Test Loss: 26.31195068359375\n",
      "Epoch: 380 Train Loss: 27.257122039794922 Test Loss: 26.19661521911621\n",
      "Epoch: 390 Train Loss: 27.08136558532715 Test Loss: 26.088930130004883\n",
      "Epoch: 400 Train Loss: 26.91539192199707 Test Loss: 25.98835563659668\n",
      "Epoch: 410 Train Loss: 26.75851821899414 Test Loss: 25.89437484741211\n",
      "Epoch: 420 Train Loss: 26.61014747619629 Test Loss: 25.80652618408203\n",
      "Epoch: 430 Train Loss: 26.46973419189453 Test Loss: 25.724367141723633\n",
      "Epoch: 440 Train Loss: 26.336740493774414 Test Loss: 25.647493362426758\n",
      "Epoch: 450 Train Loss: 26.210710525512695 Test Loss: 25.575542449951172\n",
      "Epoch: 460 Train Loss: 26.09119415283203 Test Loss: 25.50815200805664\n",
      "Epoch: 470 Train Loss: 25.977781295776367 Test Loss: 25.44501304626465\n",
      "Epoch: 480 Train Loss: 25.870075225830078 Test Loss: 25.385818481445312\n",
      "Epoch: 490 Train Loss: 25.76774024963379 Test Loss: 25.330299377441406\n",
      "Epoch: 500 Train Loss: 25.670442581176758 Test Loss: 25.278186798095703\n",
      "Epoch: 510 Train Loss: 25.577884674072266 Test Loss: 25.229259490966797\n",
      "Epoch: 520 Train Loss: 25.489749908447266 Test Loss: 25.183273315429688\n",
      "Epoch: 530 Train Loss: 25.40580177307129 Test Loss: 25.14004135131836\n",
      "Epoch: 540 Train Loss: 25.325773239135742 Test Loss: 25.099349975585938\n",
      "Epoch: 550 Train Loss: 25.249446868896484 Test Loss: 25.061038970947266\n",
      "Epoch: 560 Train Loss: 25.17660140991211 Test Loss: 25.024930953979492\n",
      "Epoch: 570 Train Loss: 25.107027053833008 Test Loss: 24.990867614746094\n",
      "Epoch: 580 Train Loss: 25.040538787841797 Test Loss: 24.95871925354004\n",
      "Epoch: 590 Train Loss: 24.976959228515625 Test Loss: 24.928333282470703\n",
      "Epoch: 600 Train Loss: 24.9161319732666 Test Loss: 24.89959144592285\n",
      "Epoch: 610 Train Loss: 24.857898712158203 Test Loss: 24.87238311767578\n",
      "Epoch: 620 Train Loss: 24.80210304260254 Test Loss: 24.846595764160156\n",
      "Epoch: 630 Train Loss: 24.748619079589844 Test Loss: 24.822118759155273\n",
      "Epoch: 640 Train Loss: 24.697322845458984 Test Loss: 24.798858642578125\n",
      "Epoch: 650 Train Loss: 24.648075103759766 Test Loss: 24.776748657226562\n",
      "Epoch: 660 Train Loss: 24.600778579711914 Test Loss: 24.755680084228516\n",
      "Epoch: 670 Train Loss: 24.555335998535156 Test Loss: 24.73558235168457\n",
      "Epoch: 680 Train Loss: 24.51163101196289 Test Loss: 24.71639060974121\n",
      "Epoch: 690 Train Loss: 24.469573974609375 Test Loss: 24.698028564453125\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    pred = train_x @ w + b\n",
    "\n",
    "    loss = mean_squared_error(pred, train_y)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * lr\n",
    "        b -= b.grad * lr\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "        \n",
    "        # Validate model\n",
    "        val_pred = test_x @ w + b\n",
    "        val_loss = mean_squared_error(val_pred, test_y)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch} Train Loss: {loss.item()} Test Loss: {val_loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
